{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e7a0b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from tensorflow import keras\n",
    "import os  \n",
    "import torch\n",
    "import time\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import psycopg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20a8968d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadRN50():\n",
    "    return [\n",
    "        ## S\n",
    "        {'c': keras.models.load_model('/Users/mh/Downloads/models/ResNet50_revised/TM_Chassis_Single/connector.h5'),\n",
    "        'ms': keras.models.load_model('/Users/mh/Downloads/models/ResNet50_revised/TM_Chassis_Single/multiscrew.h5'),\n",
    "        's1': keras.models.load_model('/Users/mh/Downloads/models/ResNet50_revised/TM_Chassis_Single/screw1.h5'),\n",
    "        's2': keras.models.load_model('/Users/mh/Downloads/models/ResNet50_revised/TM_Chassis_Single/screw2.h5'),\n",
    "        'sp2': keras.models.load_model('/Users/mh/Downloads/models/ResNet50_revised/TM_Chassis_Single/supporter2.h5'),\n",
    "        'sp3': keras.models.load_model('/Users/mh/Downloads/models/ResNet50_revised/TM_Chassis_Single/supporter3.h5')},\n",
    "        ## M\n",
    "        {'c1': keras.models.load_model('/Users/mh/Downloads/models/ResNet50_revised/TM_Chassis_MULT/connector1.h5'),\n",
    "        'c2': keras.models.load_model('/Users/mh/Downloads/models/ResNet50_revised/TM_Chassis_MULT/connector2.h5'),\n",
    "        'ms1': keras.models.load_model('/Users/mh/Downloads/models/ResNet50_revised/TM_Chassis_MULT/multiscrew1.h5'),\n",
    "        'ms2': keras.models.load_model('/Users/mh/Downloads/models/ResNet50_revised/TM_Chassis_MULT/multiscrew2.h5'),\n",
    "        's1': keras.models.load_model('/Users/mh/Downloads/models/ResNet50_revised/TM_Chassis_MULT/screw1.h5'),\n",
    "        's2': keras.models.load_model('/Users/mh/Downloads/models/ResNet50_revised/TM_Chassis_MULT/screw2.h5'),\n",
    "        'sp1': keras.models.load_model('/Users/mh/Downloads/models/ResNet50_revised/TM_Chassis_MULT/supporter1.h5'),\n",
    "        'sp2': keras.models.load_model('/Users/mh/Downloads/models/ResNet50_revised/TM_Chassis_MULT/supporter2.h5'),\n",
    "        'sp3': keras.models.load_model('/Users/mh/Downloads/models/ResNet50_revised/TM_Chassis_MULT/supporter3.h5')},\n",
    "        ## AS\n",
    "        {'c1': keras.models.load_model('/Users/mh/Downloads/models/ResNet50_revised/TM-A_Chassis_Single/connector1.h5'),\n",
    "        'c2': keras.models.load_model('/Users/mh/Downloads/models/ResNet50_revised/TM-A_Chassis_Single/connector2.h5'),\n",
    "        'ms': keras.models.load_model('/Users/mh/Downloads/models/ResNet50_revised/TM-A_Chassis_Single/multiscrew.h5'),\n",
    "        's1': keras.models.load_model('/Users/mh/Downloads/models/ResNet50_revised/TM-A_Chassis_Single/screw1.h5'),\n",
    "        's2': keras.models.load_model('/Users/mh/Downloads/models/ResNet50_revised/TM-A_Chassis_Single/screw2.h5'),\n",
    "        'sp1': keras.models.load_model('/Users/mh/Downloads/models/ResNet50_revised/TM-A_Chassis_Single/supporter1.h5'),\n",
    "        'sp2': keras.models.load_model('/Users/mh/Downloads/models/ResNet50_revised/TM-A_Chassis_Single/supporter2.h5'),\n",
    "        'sp3': keras.models.load_model('/Users/mh/Downloads/models/ResNet50_revised/TM-A_Chassis_Single/supporter3.h5'),\n",
    "        'sp4': keras.models.load_model('/Users/mh/Downloads/models/ResNet50_revised/TM-A_Chassis_Single/supporter4.h5')},\n",
    "        ## AM\n",
    "        {'c1': keras.models.load_model('/Users/mh/Downloads/models/ResNet50_revised/TM-A_Chassis_MULT/connector1.h5'),\n",
    "        'c2': keras.models.load_model('/Users/mh/Downloads/models/ResNet50_revised/TM-A_Chassis_MULT/connector2.h5'),\n",
    "        'c3': keras.models.load_model('/Users/mh/Downloads/models/ResNet50_revised/TM-A_Chassis_MULT/connector3.h5'),\n",
    "        'ms1': keras.models.load_model('/Users/mh/Downloads/models/ResNet50_revised/TM-A_Chassis_MULT/multiscrew1.h5'),\n",
    "        'ms2': keras.models.load_model('/Users/mh/Downloads/models/ResNet50_revised/TM-A_Chassis_MULT/multiscrew2.h5'),\n",
    "        's1': keras.models.load_model('/Users/mh/Downloads/models/ResNet50_revised/TM-A_Chassis_MULT/screw1.h5'),\n",
    "        's2': keras.models.load_model('/Users/mh/Downloads/models/ResNet50_revised/TM-A_Chassis_MULT/screw2.h5'),\n",
    "        'sp1': keras.models.load_model('/Users/mh/Downloads/models/ResNet50_revised/TM-A_Chassis_MULT/supporter1.h5'),\n",
    "        'sp2': keras.models.load_model('/Users/mh/Downloads/models/ResNet50_revised/TM-A_Chassis_MULT/supporter2.h5'),\n",
    "        'sp3': keras.models.load_model('/Users/mh/Downloads/models/ResNet50_revised/TM-A_Chassis_MULT/supporter3.h5')}\n",
    "    ]\n",
    "\n",
    "def connectToServer():\n",
    "    conn = None\n",
    "    try:\n",
    "        print('Connecting to the PostgreSQL database...')\n",
    "        conn = psycopg2.connect(host=\"\",\n",
    "                                database=\"\",\n",
    "                                user=\"\",\n",
    "                                password=\"\",\n",
    "                                port=)\n",
    "\n",
    "        print('PostgreSQL database version:')\n",
    "        cur = conn.cursor()\n",
    "        cur.execute('SELECT version()')\n",
    "        db_version = cur.fetchone()\n",
    "        cur.close()\n",
    "        print(db_version)\n",
    "    except (Exception, psycopg2.DatabaseError) as error:\n",
    "        print(\"Exception\")\n",
    "        print(error)\n",
    "    return conn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98b80e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def downloadImageFromServerAndGetLocalPath(id):\n",
    "    ## DB에서 id에 해당하는 튜플을 select\n",
    "    cur = CONN.cursor()\n",
    "    cur.execute(\"select image, type from public.image where id=%s\", (id, ))\n",
    "    tup = cur.fetchone()\n",
    "    cur.close()\n",
    "\n",
    "    ## select 된 튜플 이미지(binary)를 numpy.ndarray로 변환 + type 저장\n",
    "    binImage = tup[0].tobytes()\n",
    "    npImage = cv2.imdecode(np.frombuffer(binImage, np.uint8), -1)\n",
    "    datasetType = tup[1]\n",
    "\n",
    "    ## fetch한 이미지를 local에 파일로 저장\n",
    "    path = f'{round(time.time() * 1000)}.jpg'\n",
    "    cv2.imwrite(path, npImage)\n",
    "\n",
    "    ## 저장된 이미지 경로, 데이터셋 type 리턴\n",
    "    return path, datasetType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee4b9ae1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/mh/yolov5\n"
     ]
    }
   ],
   "source": [
    "%cd /Users/mh/yolov5/\n",
    "import detect\n",
    "#%cd ..\n",
    "\n",
    "def processImage(path, datasetType):\n",
    "    ## 이미지 읽기\n",
    "    image = cv2.imread(path)\n",
    "\n",
    "    ## 결과 이미지\n",
    "    result = image.copy()\n",
    "\n",
    "    ## yolo로 부품 탐지\n",
    "    yoloResults = detect.run(weights=YOLOv5_MODELS_PATH[datasetType], source=path)\n",
    "\n",
    "    ## yolo 부품 탐지 결과 순회\n",
    "    for yoloResult in yoloResults:\n",
    "        ## 결과 추출 (부품 이름, conf., 좌표값)\n",
    "        spl = yoloResult[0].split(' ')\n",
    "        part, conf = spl[0], spl[1]\n",
    "        x1, y1 = int(yoloResult[1][0]), int(yoloResult[1][1])\n",
    "        x2, y2 = int(yoloResult[1][2]), int(yoloResult[1][3])\n",
    "\n",
    "        ## 부품 crop\n",
    "        croppedImage = image[y1:y2, x1:x2]\n",
    "        croppedImage = cv2.resize(croppedImage, (224, 224))\n",
    "        croppedImage = np.expand_dims(croppedImage, axis=0)\n",
    "        \n",
    "        ## CNN으로 부품 class 분류\n",
    "        predRN50 = RN50_MODELS[datasetType][part].predict(croppedImage)\n",
    "\n",
    "        ## 결과를 원본 이미지에 그리기\n",
    "        if np.argmax(predRN50[0]) == 0:  # 정상\n",
    "            result = cv2.rectangle(result, (x1, y1), (x2, y2), (0, 255, 0), 5)\n",
    "            cv2.putText(result, part + ': Normal', (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 2.0, (0, 255, 0), 5)\n",
    "        else:  # 불량\n",
    "            result = cv2.rectangle(result, (x1, y1), (x2, y2), (0, 0, 255), 5)\n",
    "            cv2.putText(result, part + ': Defect', (x1, y1 - 15), cv2.FONT_HERSHEY_SIMPLEX, 2.0, (0, 0, 255), 5)\n",
    "    \n",
    "    ## 저장된 이미지 삭제\n",
    "    os.remove(path)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3fd05af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def uploadResultToServer(result, id):\n",
    "    #### 결과 이미지를 binary로 변환\n",
    "    _, encoded = cv2.imencode('.jpeg', result)\n",
    "    binImage = encoded.tobytes()\n",
    "\n",
    "    ### DB 튜플의 result 컬럼 update\n",
    "    cur = CONN.cursor()\n",
    "    cur.execute('''update public.image set result=%s where id=%s''', (binImage + b'1', id, ))\n",
    "    CONN.commit()\n",
    "    cur.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a79cc76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to the PostgreSQL database...\n",
      "PostgreSQL database version:\n",
      "('PostgreSQL 14.7 on x86_64-pc-linux-gnu, compiled by gcc (GCC) 7.3.1 20180712 (Red Hat 7.3.1-12), 64-bit',)\n"
     ]
    }
   ],
   "source": [
    "RN50_MODELS = loadRN50()\n",
    "CONN = connectToServer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07bb6a07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
      " * Running on http://127.0.0.1:5002\n",
      "\u001b[33mPress CTRL+C to quit\u001b[0m\n",
      "YOLOv5 🚀 v7.0-163-g016e046 Python-3.10.9 torch-2.0.1 CPU\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s summary: 157 layers, 7026307 parameters, 0 gradients\n",
      "image 1/1 /Users/mh/yolov5/1685683182333.jpg: 384x640 1 c, 1 ms, 1 s1, 1 s2, 1 sp2, 1 sp3, 45.9ms\n",
      "Speed: 0.5ms pre-process, 45.9ms inference, 0.6ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/detect/exp\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 343ms/step\n",
      "1/1 [==============================] - 0s 321ms/step\n",
      "1/1 [==============================] - 0s 320ms/step\n",
      "1/1 [==============================] - 0s 322ms/step\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x3993ad480> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 323ms/step\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x3993adc60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 335ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [02/Jun/2023 14:19:45] \"POST /process HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "#import time\n",
    "#import math\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "YOLOv5_MODELS_PATH = [\n",
    "    '/Users/mh/Downloads/models/yolo_models/best_s.pt',\n",
    "    '/Users/mh/Downloads/models/yolo_models/best_m.pt',\n",
    "    '/Users/mh/Downloads/models/yolo_models/best_as.pt',\n",
    "    '/Users/mh/Downloads/models/yolo_models/best_am.pt'\n",
    "]\n",
    "\n",
    "@app.route('/')\n",
    "def hello(): # Web 기본 접속 화면 (주소 입력하고 들어가면 나오는 default 화면)\n",
    "  return \"<h1>Welcome to Flask</h1>\"\n",
    "\n",
    "@app.route('/process', methods=['POST'])\n",
    "def handle_request():\n",
    "  fail = False\n",
    "  value = request.json.get('value') # image id (DB)\n",
    "\n",
    "  #DB_start = time.time()\n",
    "  path, datasetType = downloadImageFromServerAndGetLocalPath(value)\n",
    "  #PRO_start = time.time()\n",
    "  result = processImage(path, datasetType)\n",
    "  #PRO_end = time.time()\n",
    "  uploadResultToServer(result, value)\n",
    "  #DB_end = time.time()\n",
    "    \n",
    "  #print(f'이미지 프로세싱 타임 (only processing): {PRO_end - PRO_start}')\n",
    "  #print(f'이미지 프로세싱 타임 (considering DB): {DB_end - DB_start}')\n",
    "  \n",
    "  if fail:\n",
    "    return jsonify({'result': -1})\n",
    "      \n",
    "  return jsonify({'result': value}) # 완료 후 image id 반환\n",
    "  \n",
    "if __name__ == '__main__':\n",
    "  app.run(port='5002')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7296c052",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CNN",
   "language": "python",
   "name": "cnn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
