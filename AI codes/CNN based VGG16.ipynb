{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6b98453",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e9472677",
   "metadata": {},
   "outputs": [],
   "source": [
    "folders = ['TM_Chassis_MULT', 'TM_Chassis_Single', 'TM-A_Chassis_MULT', 'TM-A_Chassis_Single']\n",
    "PCB_num = 0\n",
    "\n",
    "folder = folders[PCB_num]\n",
    "\n",
    "dataset_dir = f\"/Users/mh/Downloads/datasets/{folder}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9b1bbdcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 screw2\n",
      "1 connector1\n",
      "2 supporter1\n",
      "3 multiscrew2\n",
      "4 connector2\n",
      "5 screw1\n",
      "6 supporter3\n",
      "7 supporter2\n",
      "8 multiscrew1\n"
     ]
    }
   ],
   "source": [
    "parts = os.listdir(dataset_dir)\n",
    "\n",
    "i = 0\n",
    "for part in parts:\n",
    "    print(i, end=\" \")\n",
    "    print(part)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bcee9680",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/mh/Downloads/datasets/TM_Chassis_MULT/screw2\n"
     ]
    }
   ],
   "source": [
    "part_num = 0\n",
    "PART_NAME = parts[part_num]\n",
    "\n",
    "data_dir = f\"{dataset_dir}/{PART_NAME}\"\n",
    "print(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0e6b57e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "432 168 168\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 32\n",
    "IMAGE_SIZE = 224\n",
    "\n",
    "TRAIN_DIR = f\"{data_dir}/train\"\n",
    "VAL_DIR = f\"{data_dir}/test\"\n",
    "TEST_DIR = f\"{data_dir}/valid\"\n",
    "\n",
    "TRAIN_TOTAL = len(os.listdir(TRAIN_DIR + '/correct')) + len(os.listdir(TRAIN_DIR + '/incorrect'))\n",
    "VAL_TOTAL = len(os.listdir(VAL_DIR + '/correct')) + len(os.listdir(VAL_DIR + '/incorrect'))\n",
    "TEST_TOTAL = len(os.listdir(TEST_DIR + '/correct')) + len(os.listdir(TEST_DIR + '/incorrect'))\n",
    "\n",
    "print(TRAIN_TOTAL, VAL_TOTAL, TEST_TOTAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f20da93f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 432 images belonging to 2 classes.\n",
      "Found 168 images belonging to 2 classes.\n",
      "Found 168 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "trainIdg = ImageDataGenerator(\n",
    "    rescale = 1.0 / 255,\n",
    "    rotation_range = 1,\n",
    "    width_shift_range = 0.1,\n",
    "    height_shift_range = 0.1,\n",
    "    shear_range = 0.2,\n",
    "    zoom_range = 0.2\n",
    ")\n",
    "trainGen = trainIdg.flow_from_directory(\n",
    "    TRAIN_DIR,\n",
    "    target_size = (IMAGE_SIZE, IMAGE_SIZE),\n",
    "    class_mode = 'binary',\n",
    "    batch_size = BATCH_SIZE,\n",
    "    shuffle = True\n",
    ")\n",
    "\n",
    "valIdg = ImageDataGenerator(rescale = 1.0 / 255)\n",
    "valGen = valIdg.flow_from_directory(\n",
    "    VAL_DIR,\n",
    "    target_size = (IMAGE_SIZE, IMAGE_SIZE),\n",
    "    class_mode = 'binary',\n",
    "    batch_size = BATCH_SIZE\n",
    ")\n",
    "\n",
    "testIdg = ImageDataGenerator(rescale = 1.0 / 255)\n",
    "testGen = testIdg.flow_from_directory(\n",
    "    TEST_DIR,\n",
    "    target_size = (IMAGE_SIZE, IMAGE_SIZE),\n",
    "    class_mode = 'binary',\n",
    "    batch_size = BATCH_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fa3cb111",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseModel = VGG16(\n",
    "    include_top = False,\n",
    "    weights = \"imagenet\",\n",
    "    input_shape = (224, 224, 3)\n",
    ")\n",
    "baseModel.trainable = False\n",
    "\n",
    "out = baseModel.get_layer('block5_pool').output  # the output of the base model\n",
    "x = keras.layers.GlobalMaxPooling2D()(out)\n",
    "x = keras.layers.Dense(512, activation='relu')(x)\n",
    "x = keras.layers.Dropout(0.5)(x)\n",
    "x = keras.layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "model = keras.Model(baseModel.input, x)  # the final CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "621badad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_36\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_37 (InputLayer)       [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      " global_max_pooling2d_36 (Gl  (None, 512)              0         \n",
      " obalMaxPooling2D)                                               \n",
      "                                                                 \n",
      " dense_72 (Dense)            (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout_36 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_73 (Dense)            (None, 1)                 513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,977,857\n",
      "Trainable params: 263,169\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "43213461",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<multiscrew1>\n",
      "Epoch 1/10\n",
      "13/13 [==============================] - 32s 3s/step - loss: 0.3636 - binary_accuracy: 0.8675 - val_loss: 0.0788 - val_binary_accuracy: 1.0000\n",
      "Epoch 2/10\n",
      "13/13 [==============================] - 33s 3s/step - loss: 0.0422 - binary_accuracy: 1.0000 - val_loss: 0.0085 - val_binary_accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "13/13 [==============================] - 33s 3s/step - loss: 0.0099 - binary_accuracy: 1.0000 - val_loss: 0.0035 - val_binary_accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "13/13 [==============================] - 33s 3s/step - loss: 0.0039 - binary_accuracy: 1.0000 - val_loss: 0.0023 - val_binary_accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "13/13 [==============================] - 33s 3s/step - loss: 0.0031 - binary_accuracy: 1.0000 - val_loss: 0.0016 - val_binary_accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "13/13 [==============================] - 34s 3s/step - loss: 0.0024 - binary_accuracy: 1.0000 - val_loss: 0.0011 - val_binary_accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "13/13 [==============================] - 33s 3s/step - loss: 0.0017 - binary_accuracy: 1.0000 - val_loss: 8.6000e-04 - val_binary_accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "13/13 [==============================] - 33s 3s/step - loss: 0.0016 - binary_accuracy: 1.0000 - val_loss: 7.1469e-04 - val_binary_accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "13/13 [==============================] - 33s 3s/step - loss: 0.0011 - binary_accuracy: 1.0000 - val_loss: 5.0081e-04 - val_binary_accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "13/13 [==============================] - 33s 3s/step - loss: 0.0011 - binary_accuracy: 1.0000 - val_loss: 3.7759e-04 - val_binary_accuracy: 1.0000\n",
      "\n",
      "multiscrew1 saved..\n"
     ]
    }
   ],
   "source": [
    "print(f\"<{part}>\")\n",
    "\n",
    "model.compile(\n",
    "    optimizer = keras.optimizers.Adam(),\n",
    "    loss = keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "    metrics = [keras.metrics.BinaryAccuracy()]\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    trainGen,\n",
    "    epochs = 10,\n",
    "    validation_data = valGen,\n",
    "    steps_per_epoch = TRAIN_TOTAL // BATCH_SIZE,\n",
    "    validation_steps = VAL_TOTAL // BATCH_SIZE,\n",
    "    batch_size = BATCH_SIZE\n",
    ")\n",
    "\n",
    "if not os.path.exists(f\"/Users/mh/Downloads/models/{folder}\"):\n",
    "  os.makedirs(f\"/Users/mh/Downloads/models/{folder}\")\n",
    "model.save(f'/Users/mh/Downloads/models/{folder}/{PART_NAME}.h5')\n",
    "\n",
    "print()\n",
    "print(f\"{part} saved..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d45fd87",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(testGen, verbose=2)\n",
    "print('\\nTest accuracy: ', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "be582b61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<screw2>\n",
      "Found 432 images belonging to 2 classes.\n",
      "Found 168 images belonging to 2 classes.\n",
      "Found 168 images belonging to 2 classes.\n",
      "Epoch 1/10\n",
      "13/13 [==============================] - 32s 3s/step - loss: 0.1966 - binary_accuracy: 0.9225 - val_loss: 0.0145 - val_binary_accuracy: 1.0000\n",
      "Epoch 2/10\n",
      "13/13 [==============================] - 33s 3s/step - loss: 0.0191 - binary_accuracy: 0.9975 - val_loss: 0.0024 - val_binary_accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "13/13 [==============================] - 33s 3s/step - loss: 0.0050 - binary_accuracy: 1.0000 - val_loss: 9.0995e-04 - val_binary_accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "13/13 [==============================] - 33s 3s/step - loss: 0.0039 - binary_accuracy: 1.0000 - val_loss: 8.0430e-04 - val_binary_accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "13/13 [==============================] - 33s 3s/step - loss: 0.0030 - binary_accuracy: 1.0000 - val_loss: 6.8083e-04 - val_binary_accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "13/13 [==============================] - 33s 3s/step - loss: 0.0047 - binary_accuracy: 0.9975 - val_loss: 5.8846e-04 - val_binary_accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "13/13 [==============================] - 33s 3s/step - loss: 0.0021 - binary_accuracy: 1.0000 - val_loss: 4.1455e-04 - val_binary_accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "13/13 [==============================] - 33s 3s/step - loss: 0.0011 - binary_accuracy: 1.0000 - val_loss: 2.2097e-04 - val_binary_accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "13/13 [==============================] - 33s 3s/step - loss: 0.0013 - binary_accuracy: 1.0000 - val_loss: 1.6153e-04 - val_binary_accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "13/13 [==============================] - 34s 3s/step - loss: 8.9833e-04 - binary_accuracy: 1.0000 - val_loss: 1.6378e-04 - val_binary_accuracy: 1.0000\n",
      "\n",
      "screw2 saved..\n",
      "\n",
      "\n",
      "<connector1>\n",
      "Found 288 images belonging to 2 classes.\n",
      "Found 112 images belonging to 2 classes.\n",
      "Found 112 images belonging to 2 classes.\n",
      "Epoch 1/10\n",
      "9/9 [==============================] - 23s 3s/step - loss: 0.4875 - binary_accuracy: 0.7917 - val_loss: 0.0451 - val_binary_accuracy: 1.0000\n",
      "Epoch 2/10\n",
      "9/9 [==============================] - 23s 3s/step - loss: 0.0448 - binary_accuracy: 0.9931 - val_loss: 0.0018 - val_binary_accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "9/9 [==============================] - 23s 3s/step - loss: 0.0150 - binary_accuracy: 0.9965 - val_loss: 4.9450e-04 - val_binary_accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "9/9 [==============================] - 23s 3s/step - loss: 0.0032 - binary_accuracy: 1.0000 - val_loss: 9.9529e-04 - val_binary_accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "9/9 [==============================] - 23s 3s/step - loss: 0.0038 - binary_accuracy: 1.0000 - val_loss: 2.1321e-04 - val_binary_accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "9/9 [==============================] - 23s 3s/step - loss: 0.0010 - binary_accuracy: 1.0000 - val_loss: 1.0347e-04 - val_binary_accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "9/9 [==============================] - 23s 3s/step - loss: 0.0043 - binary_accuracy: 0.9965 - val_loss: 2.0020e-04 - val_binary_accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "9/9 [==============================] - 23s 3s/step - loss: 0.0010 - binary_accuracy: 1.0000 - val_loss: 1.8338e-04 - val_binary_accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "9/9 [==============================] - 23s 3s/step - loss: 8.2658e-04 - binary_accuracy: 1.0000 - val_loss: 1.1294e-04 - val_binary_accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "9/9 [==============================] - 23s 3s/step - loss: 5.7706e-04 - binary_accuracy: 1.0000 - val_loss: 7.7297e-05 - val_binary_accuracy: 1.0000\n",
      "\n",
      "connector1 saved..\n",
      "\n",
      "\n",
      "<supporter1>\n",
      "Found 576 images belonging to 2 classes.\n",
      "Found 224 images belonging to 2 classes.\n",
      "Found 224 images belonging to 2 classes.\n",
      "Epoch 1/10\n",
      "18/18 [==============================] - 48s 3s/step - loss: 0.3886 - binary_accuracy: 0.8194 - val_loss: 0.2906 - val_binary_accuracy: 0.7812\n",
      "Epoch 2/10\n",
      "18/18 [==============================] - 48s 3s/step - loss: 0.1874 - binary_accuracy: 0.9167 - val_loss: 0.0523 - val_binary_accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "18/18 [==============================] - 49s 3s/step - loss: 0.0953 - binary_accuracy: 0.9740 - val_loss: 0.0267 - val_binary_accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "18/18 [==============================] - 48s 3s/step - loss: 0.0573 - binary_accuracy: 0.9878 - val_loss: 0.0380 - val_binary_accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "18/18 [==============================] - 48s 3s/step - loss: 0.0399 - binary_accuracy: 0.9965 - val_loss: 0.0242 - val_binary_accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "18/18 [==============================] - 48s 3s/step - loss: 0.0316 - binary_accuracy: 0.9931 - val_loss: 0.0315 - val_binary_accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "18/18 [==============================] - 49s 3s/step - loss: 0.0266 - binary_accuracy: 0.9948 - val_loss: 0.0188 - val_binary_accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "18/18 [==============================] - 49s 3s/step - loss: 0.0250 - binary_accuracy: 0.9983 - val_loss: 0.0128 - val_binary_accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "18/18 [==============================] - 49s 3s/step - loss: 0.0153 - binary_accuracy: 1.0000 - val_loss: 0.0084 - val_binary_accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "18/18 [==============================] - 48s 3s/step - loss: 0.0141 - binary_accuracy: 0.9983 - val_loss: 0.0101 - val_binary_accuracy: 1.0000\n",
      "\n",
      "supporter1 saved..\n",
      "\n",
      "\n",
      "<multiscrew>\n",
      "Found 1296 images belonging to 2 classes.\n",
      "Found 504 images belonging to 2 classes.\n",
      "Found 504 images belonging to 2 classes.\n",
      "Epoch 1/10\n",
      "40/40 [==============================] - 104s 3s/step - loss: 0.3317 - binary_accuracy: 0.9011 - val_loss: 0.1474 - val_binary_accuracy: 0.9062\n",
      "Epoch 2/10\n",
      "40/40 [==============================] - 104s 3s/step - loss: 0.0847 - binary_accuracy: 0.9731 - val_loss: 0.0212 - val_binary_accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "40/40 [==============================] - 104s 3s/step - loss: 0.0390 - binary_accuracy: 0.9968 - val_loss: 0.0144 - val_binary_accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "40/40 [==============================] - 104s 3s/step - loss: 0.0230 - binary_accuracy: 0.9976 - val_loss: 0.0042 - val_binary_accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "40/40 [==============================] - 104s 3s/step - loss: 0.0160 - binary_accuracy: 0.9984 - val_loss: 0.0028 - val_binary_accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "40/40 [==============================] - 104s 3s/step - loss: 0.0071 - binary_accuracy: 1.0000 - val_loss: 0.0015 - val_binary_accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "40/40 [==============================] - 104s 3s/step - loss: 0.0069 - binary_accuracy: 1.0000 - val_loss: 0.0013 - val_binary_accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "40/40 [==============================] - 104s 3s/step - loss: 0.0060 - binary_accuracy: 1.0000 - val_loss: 8.0224e-04 - val_binary_accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "40/40 [==============================] - 104s 3s/step - loss: 0.0048 - binary_accuracy: 1.0000 - val_loss: 8.9952e-04 - val_binary_accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "40/40 [==============================] - 104s 3s/step - loss: 0.0038 - binary_accuracy: 1.0000 - val_loss: 4.2067e-04 - val_binary_accuracy: 1.0000\n",
      "\n",
      "multiscrew saved..\n",
      "\n",
      "\n",
      "<connector2>\n",
      "Found 288 images belonging to 2 classes.\n",
      "Found 112 images belonging to 2 classes.\n",
      "Found 112 images belonging to 2 classes.\n",
      "Epoch 1/10\n",
      "9/9 [==============================] - 23s 3s/step - loss: 0.3229 - binary_accuracy: 0.8646 - val_loss: 0.0776 - val_binary_accuracy: 1.0000\n",
      "Epoch 2/10\n",
      "9/9 [==============================] - 23s 3s/step - loss: 0.0389 - binary_accuracy: 1.0000 - val_loss: 0.0249 - val_binary_accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "9/9 [==============================] - 23s 3s/step - loss: 0.0167 - binary_accuracy: 1.0000 - val_loss: 0.0098 - val_binary_accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "9/9 [==============================] - 23s 3s/step - loss: 0.0090 - binary_accuracy: 1.0000 - val_loss: 0.0052 - val_binary_accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "9/9 [==============================] - 23s 3s/step - loss: 0.0050 - binary_accuracy: 1.0000 - val_loss: 0.0049 - val_binary_accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "9/9 [==============================] - 23s 3s/step - loss: 0.0029 - binary_accuracy: 1.0000 - val_loss: 0.0028 - val_binary_accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "9/9 [==============================] - 23s 3s/step - loss: 0.0031 - binary_accuracy: 1.0000 - val_loss: 0.0026 - val_binary_accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "9/9 [==============================] - 23s 3s/step - loss: 0.0018 - binary_accuracy: 1.0000 - val_loss: 0.0026 - val_binary_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10\n",
      "9/9 [==============================] - 23s 3s/step - loss: 0.0018 - binary_accuracy: 1.0000 - val_loss: 0.0018 - val_binary_accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "9/9 [==============================] - 23s 3s/step - loss: 0.0015 - binary_accuracy: 1.0000 - val_loss: 0.0013 - val_binary_accuracy: 1.0000\n",
      "\n",
      "connector2 saved..\n",
      "\n",
      "\n",
      "<screw1>\n",
      "Found 288 images belonging to 2 classes.\n",
      "Found 112 images belonging to 2 classes.\n",
      "Found 112 images belonging to 2 classes.\n",
      "Epoch 1/10\n",
      "9/9 [==============================] - 23s 3s/step - loss: 0.5517 - binary_accuracy: 0.6944 - val_loss: 0.3105 - val_binary_accuracy: 1.0000\n",
      "Epoch 2/10\n",
      "9/9 [==============================] - 23s 3s/step - loss: 0.2349 - binary_accuracy: 0.9271 - val_loss: 0.1247 - val_binary_accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "9/9 [==============================] - 23s 3s/step - loss: 0.0760 - binary_accuracy: 1.0000 - val_loss: 0.0395 - val_binary_accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "9/9 [==============================] - 23s 3s/step - loss: 0.0342 - binary_accuracy: 1.0000 - val_loss: 0.0341 - val_binary_accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "9/9 [==============================] - 23s 3s/step - loss: 0.0207 - binary_accuracy: 1.0000 - val_loss: 0.0148 - val_binary_accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "9/9 [==============================] - 23s 3s/step - loss: 0.0151 - binary_accuracy: 1.0000 - val_loss: 0.0141 - val_binary_accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "9/9 [==============================] - 23s 3s/step - loss: 0.0103 - binary_accuracy: 1.0000 - val_loss: 0.0110 - val_binary_accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "9/9 [==============================] - 23s 3s/step - loss: 0.0092 - binary_accuracy: 1.0000 - val_loss: 0.0076 - val_binary_accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "9/9 [==============================] - 23s 3s/step - loss: 0.0084 - binary_accuracy: 1.0000 - val_loss: 0.0067 - val_binary_accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "9/9 [==============================] - 23s 3s/step - loss: 0.0062 - binary_accuracy: 1.0000 - val_loss: 0.0058 - val_binary_accuracy: 1.0000\n",
      "\n",
      "screw1 saved..\n",
      "\n",
      "\n",
      "<supporter4>\n",
      "Found 432 images belonging to 2 classes.\n",
      "Found 168 images belonging to 2 classes.\n",
      "Found 168 images belonging to 2 classes.\n",
      "Epoch 1/10\n",
      "13/13 [==============================] - 33s 3s/step - loss: 0.5060 - binary_accuracy: 0.8175 - val_loss: 0.0500 - val_binary_accuracy: 1.0000\n",
      "Epoch 2/10\n",
      "13/13 [==============================] - 33s 3s/step - loss: 0.0509 - binary_accuracy: 1.0000 - val_loss: 0.0090 - val_binary_accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "13/13 [==============================] - 33s 3s/step - loss: 0.0147 - binary_accuracy: 1.0000 - val_loss: 0.0032 - val_binary_accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "13/13 [==============================] - 33s 3s/step - loss: 0.0095 - binary_accuracy: 1.0000 - val_loss: 0.0016 - val_binary_accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "13/13 [==============================] - 34s 3s/step - loss: 0.0048 - binary_accuracy: 1.0000 - val_loss: 9.9741e-04 - val_binary_accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "13/13 [==============================] - 33s 3s/step - loss: 0.0035 - binary_accuracy: 1.0000 - val_loss: 6.5792e-04 - val_binary_accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "13/13 [==============================] - 33s 3s/step - loss: 0.0026 - binary_accuracy: 1.0000 - val_loss: 5.2530e-04 - val_binary_accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "13/13 [==============================] - 33s 3s/step - loss: 0.0020 - binary_accuracy: 1.0000 - val_loss: 4.3645e-04 - val_binary_accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "13/13 [==============================] - 33s 3s/step - loss: 0.0014 - binary_accuracy: 1.0000 - val_loss: 3.9317e-04 - val_binary_accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "13/13 [==============================] - 34s 3s/step - loss: 0.0013 - binary_accuracy: 1.0000 - val_loss: 3.0990e-04 - val_binary_accuracy: 1.0000\n",
      "\n",
      "supporter4 saved..\n",
      "\n",
      "\n",
      "<supporter3>\n",
      "Found 288 images belonging to 2 classes.\n",
      "Found 112 images belonging to 2 classes.\n",
      "Found 112 images belonging to 2 classes.\n",
      "Epoch 1/10\n",
      "9/9 [==============================] - 23s 3s/step - loss: 0.4216 - binary_accuracy: 0.8160 - val_loss: 0.0561 - val_binary_accuracy: 1.0000\n",
      "Epoch 2/10\n",
      "9/9 [==============================] - 23s 3s/step - loss: 0.0416 - binary_accuracy: 1.0000 - val_loss: 0.0049 - val_binary_accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "9/9 [==============================] - 23s 3s/step - loss: 0.0095 - binary_accuracy: 1.0000 - val_loss: 0.0012 - val_binary_accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "9/9 [==============================] - 23s 3s/step - loss: 0.0044 - binary_accuracy: 1.0000 - val_loss: 8.6161e-04 - val_binary_accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "9/9 [==============================] - 23s 3s/step - loss: 0.0036 - binary_accuracy: 1.0000 - val_loss: 5.2423e-04 - val_binary_accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "9/9 [==============================] - 23s 3s/step - loss: 0.0020 - binary_accuracy: 1.0000 - val_loss: 3.0794e-04 - val_binary_accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "9/9 [==============================] - 23s 3s/step - loss: 9.6470e-04 - binary_accuracy: 1.0000 - val_loss: 2.0573e-04 - val_binary_accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "9/9 [==============================] - 23s 3s/step - loss: 8.5221e-04 - binary_accuracy: 1.0000 - val_loss: 1.8122e-04 - val_binary_accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "9/9 [==============================] - 23s 3s/step - loss: 9.1629e-04 - binary_accuracy: 1.0000 - val_loss: 1.3820e-04 - val_binary_accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "9/9 [==============================] - 23s 3s/step - loss: 9.2209e-04 - binary_accuracy: 1.0000 - val_loss: 1.3606e-04 - val_binary_accuracy: 1.0000\n",
      "\n",
      "supporter3 saved..\n",
      "\n",
      "\n",
      "<supporter2>\n",
      "Found 432 images belonging to 2 classes.\n",
      "Found 168 images belonging to 2 classes.\n",
      "Found 168 images belonging to 2 classes.\n",
      "Epoch 1/10\n",
      "13/13 [==============================] - 33s 3s/step - loss: 0.5502 - binary_accuracy: 0.7350 - val_loss: 0.4335 - val_binary_accuracy: 0.6812\n",
      "Epoch 2/10\n",
      "13/13 [==============================] - 33s 3s/step - loss: 0.3476 - binary_accuracy: 0.8600 - val_loss: 0.2217 - val_binary_accuracy: 0.9937\n",
      "Epoch 3/10\n",
      "13/13 [==============================] - 33s 3s/step - loss: 0.2632 - binary_accuracy: 0.9050 - val_loss: 0.1589 - val_binary_accuracy: 0.9375\n",
      "Epoch 4/10\n",
      "13/13 [==============================] - 33s 3s/step - loss: 0.1771 - binary_accuracy: 0.9500 - val_loss: 0.1258 - val_binary_accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "13/13 [==============================] - 33s 3s/step - loss: 0.1410 - binary_accuracy: 0.9600 - val_loss: 0.0957 - val_binary_accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "13/13 [==============================] - 33s 3s/step - loss: 0.1088 - binary_accuracy: 0.9800 - val_loss: 0.0663 - val_binary_accuracy: 0.9937\n",
      "Epoch 7/10\n",
      "13/13 [==============================] - 33s 3s/step - loss: 0.0842 - binary_accuracy: 0.9825 - val_loss: 0.1078 - val_binary_accuracy: 0.9375\n",
      "Epoch 8/10\n",
      "13/13 [==============================] - 33s 3s/step - loss: 0.0777 - binary_accuracy: 0.9775 - val_loss: 0.0938 - val_binary_accuracy: 0.9312\n",
      "Epoch 9/10\n",
      "13/13 [==============================] - 33s 3s/step - loss: 0.0512 - binary_accuracy: 0.9925 - val_loss: 0.0636 - val_binary_accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "13/13 [==============================] - 33s 3s/step - loss: 0.0451 - binary_accuracy: 0.9975 - val_loss: 0.0495 - val_binary_accuracy: 1.0000\n",
      "\n",
      "supporter2 saved..\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "parts = os.listdir(dataset_dir)\n",
    "\n",
    "i = 0\n",
    "for part in parts:\n",
    "    print(f\"<{part}>\")\n",
    "    data_dir = f\"{dataset_dir}/{part}\"\n",
    "    \n",
    "    BATCH_SIZE = 32\n",
    "    IMAGE_SIZE = 224\n",
    "\n",
    "    TRAIN_DIR = f\"{data_dir}/train\"\n",
    "    VAL_DIR = f\"{data_dir}/test\"\n",
    "    TEST_DIR = f\"{data_dir}/valid\"\n",
    "    \n",
    "    TRAIN_TOTAL = len(os.listdir(TRAIN_DIR + '/correct')) + len(os.listdir(TRAIN_DIR + '/incorrect'))\n",
    "    VAL_TOTAL = len(os.listdir(VAL_DIR + '/correct')) + len(os.listdir(VAL_DIR + '/incorrect'))\n",
    "    TEST_TOTAL = len(os.listdir(TEST_DIR + '/correct')) + len(os.listdir(TEST_DIR + '/incorrect'))\n",
    "\n",
    "    trainIdg = ImageDataGenerator(\n",
    "        rescale = 1.0 / 255,\n",
    "        rotation_range = 1,\n",
    "        width_shift_range = 0.1,\n",
    "        height_shift_range = 0.1,\n",
    "        shear_range = 0.2,\n",
    "        zoom_range = 0.2\n",
    "    )\n",
    "    trainGen = trainIdg.flow_from_directory(\n",
    "        TRAIN_DIR,\n",
    "        target_size = (IMAGE_SIZE, IMAGE_SIZE),\n",
    "        class_mode = 'binary',\n",
    "        batch_size = BATCH_SIZE,\n",
    "        shuffle = True\n",
    "    )\n",
    "\n",
    "    valIdg = ImageDataGenerator(rescale = 1.0 / 255)\n",
    "    valGen = valIdg.flow_from_directory(\n",
    "        VAL_DIR,\n",
    "        target_size = (IMAGE_SIZE, IMAGE_SIZE),\n",
    "        class_mode = 'binary',\n",
    "        batch_size = BATCH_SIZE\n",
    "    )\n",
    "\n",
    "    testIdg = ImageDataGenerator(rescale = 1.0 / 255)\n",
    "    testGen = testIdg.flow_from_directory(\n",
    "        TEST_DIR,\n",
    "        target_size = (IMAGE_SIZE, IMAGE_SIZE),\n",
    "        class_mode = 'binary',\n",
    "        batch_size = BATCH_SIZE\n",
    "    )\n",
    "    \n",
    "    baseModel = VGG16(\n",
    "        include_top = False,\n",
    "        weights = \"imagenet\",\n",
    "        input_shape = (224, 224, 3)\n",
    "    )\n",
    "    baseModel.trainable = False\n",
    "\n",
    "    out = baseModel.get_layer('block5_pool').output  # the output of the base model\n",
    "    x = keras.layers.GlobalMaxPooling2D()(out)\n",
    "    x = keras.layers.Dense(512, activation='relu')(x)\n",
    "    x = keras.layers.Dropout(0.5)(x)\n",
    "    x = keras.layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    model = keras.Model(baseModel.input, x)  # the final CNN model\n",
    "    \n",
    "\n",
    "    model.compile(\n",
    "        optimizer = keras.optimizers.Adam(),\n",
    "        loss = keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "        metrics = [keras.metrics.BinaryAccuracy()]\n",
    "    )\n",
    "\n",
    "    history = model.fit(\n",
    "        trainGen,\n",
    "        epochs = 10,\n",
    "        validation_data = valGen,\n",
    "        steps_per_epoch = TRAIN_TOTAL // BATCH_SIZE,\n",
    "        validation_steps = VAL_TOTAL // BATCH_SIZE,\n",
    "        batch_size = BATCH_SIZE\n",
    "    )\n",
    "\n",
    "    if not os.path.exists(f\"/Users/mh/Downloads/models/VCG16/{folder}\"):\n",
    "      os.makedirs(f\"/Users/mh/Downloads/models/VCG16/{folder}\")\n",
    "    model.save(f'/Users/mh/Downloads/models/VCG16/{folder}/{part}.h5')\n",
    "\n",
    "    print()\n",
    "    print(f\"{part} saved..\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ea151a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CNN",
   "language": "python",
   "name": "cnn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
